ECOZ2 C version: 0.3.2
num_actual_sequences: 61
val_auto = 0.3
ecoz2_set_random_seed: seed=-1; actual seed=16807

--- hmm_learn ---  (use_par=1)
num_sequences = 61
epsilon = 1e-05
    0: data/sequences/TRAIN/M2048/G/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__11741.542_11743.282.seq
    1: data/sequences/TRAIN/M2048/G/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__11753.45_11755.78.seq
  ...
   59: data/sequences/TRAIN/M2048/G/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__9344.529_9346.049.seq
   60: data/sequences/TRAIN/M2048/G/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__9876.975_9879.002.seq

N=12 M=2048 type=3  #sequences = 61  max_T=181
val_auto = 0.3   log=-1.20397   max_iterations=10
estimating initial B matrix ...  (given max_T=181)
num_not_emitting_states=0
initial B matrix took 0.109s
refinement info prepared
.   1: Δ =   +241.668  sum_log_prob =   -37812.9  prev =   -38054.6  'G'  (0.341s)
.   2: Δ =   +57.8003  sum_log_prob =   -37755.1  prev =   -37812.9  'G'  (0.378s)
.   3: Δ =   +94.6757  sum_log_prob =   -37660.5  prev =   -37755.1  'G'  (0.377s)
.   4: Δ =   +109.567  sum_log_prob =   -37550.9  prev =   -37660.5  'G'  (0.391s)
.   5: Δ =   +216.516  sum_log_prob =   -37334.4  prev =   -37550.9  'G'  (0.381s)
.   6: Δ =   +499.549  sum_log_prob =   -36834.8  prev =   -37334.4  'G'  (0.390s)
.   7: Δ =   +375.362  sum_log_prob =   -36459.5  prev =   -36834.8  'G'  (0.382s)
.   8: Δ =   +269.271  sum_log_prob =   -36190.2  prev =   -36459.5  'G'  (0.390s)
.   9: Δ =   +362.824  sum_log_prob =   -35827.4  prev =   -36190.2  'G'  (0.377s)
.  10: Δ =   +358.586  sum_log_prob =   -35468.8  prev =   -35827.4  'G'  (0.380s)


	Model: data/hmms/N12__M2048_t3__a0.3_I10/G.hmm   className: 'G'
	N=12 M=2048 type: cascade-3
	restriction: 1e-05
	        #sequences: 61
	        auto value: 0.3
	      #refinements: 10
	          Σ log(P): -35468.8
=> training took 3.898s     class=G

