ECOZ2 C version: 0.3.2
num_actual_sequences: 571
val_auto = 0.3
ecoz2_set_random_seed: seed=-1; actual seed=16807

--- hmm_learn ---  (use_par=1)
num_sequences = 571
epsilon = 1e-05
    0: data/sequences/TRAIN/M2048/E/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__10206.742_10207.303.seq
    1: data/sequences/TRAIN/M2048/E/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__10208.361_10209.118.seq
  ...
  569: data/sequences/TRAIN/M2048/E/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__9820.538_9821.37.seq
  570: data/sequences/TRAIN/M2048/E/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__9822.233_9823.005.seq

N=20 M=2048 type=3  #sequences = 571  max_T=95
val_auto = 0.3   log=-1.20397   max_iterations=10
estimating initial B matrix ...  (given max_T=95)
num_not_emitting_states=0
initial B matrix took 1.370s
refinement info prepared
.   1: Δ =   +4445.73  sum_log_prob =    -167030  prev =    -171476  'E'  (2.812s)
.   2: Δ =   +2819.14  sum_log_prob =    -164211  prev =    -167030  'E'  (2.908s)
.   3: Δ =   +2252.29  sum_log_prob =    -161959  prev =    -164211  'E'  (3.110s)
.   4: Δ =   +1481.53  sum_log_prob =    -160477  prev =    -161959  'E'  (3.007s)
.   5: Δ =   +1407.86  sum_log_prob =    -159069  prev =    -160477  'E'  (2.975s)
.   6: Δ =    +1444.7  sum_log_prob =    -157625  prev =    -159069  'E'  (2.926s)
.   7: Δ =   +1796.51  sum_log_prob =    -155828  prev =    -157625  'E'  (2.912s)
.   8: Δ =   +2416.06  sum_log_prob =    -153412  prev =    -155828  'E'  (2.961s)
.   9: Δ =   +1414.84  sum_log_prob =    -151997  prev =    -153412  'E'  (2.812s)
.  10: Δ =   +1004.62  sum_log_prob =    -150993  prev =    -151997  'E'  (2.919s)


	Model: data/hmms/N20__M2048_t3__a0.3_I10/E.hmm   className: 'E'
	N=20 M=2048 type: cascade-3
	restriction: 1e-05
	        #sequences: 571
	        auto value: 0.3
	      #refinements: 10
	          Σ log(P): -150993
=> training took 30.723s     class=E

