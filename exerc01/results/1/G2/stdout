ECOZ2 C version: 0.3.3
num_actual_sequences: 246
val_auto = 0.3
ecoz2_set_random_seed: seed=-1; actual seed=16807

--- hmm_learn ---  (use_par=1)
num_sequences = 246
epsilon = 1e-05
    0: data/sequences/TRAIN/M4096/G2/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__10306.18_10308.116.seq
    1: data/sequences/TRAIN/M4096/G2/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__10322.944_10324.457.seq
  ...
  244: data/sequences/TRAIN/M4096/G2/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__9941.566_9943.761.seq
  245: data/sequences/TRAIN/M4096/G2/from_MARS_20161221_000046_SongSession_16kHz_HPF5Hz.wav__9956.758_9958.146.seq

N=20 M=4096 type=3  #sequences = 246  max_T=307
val_auto = 0.3   log=-1.20397   max_iterations=10
estimating initial B matrix ...  (given max_T=307)
num_not_emitting_states=0
initial B matrix took 1.776s
refinement info prepared
.   1: Δ =   +2055.93  sum_log_prob =    -207254  prev =    -209310  'G2'  (5.922s)
.   2: Δ =    +696.37  sum_log_prob =    -206558  prev =    -207254  'G2'  (6.032s)
.   3: Δ =   +1017.28  sum_log_prob =    -205540  prev =    -206558  'G2'  (6.068s)
.   4: Δ =   +1626.68  sum_log_prob =    -203914  prev =    -205540  'G2'  (5.686s)
.   5: Δ =   +1321.08  sum_log_prob =    -202593  prev =    -203914  'G2'  (5.853s)
.   6: Δ =   +1249.48  sum_log_prob =    -201343  prev =    -202593  'G2'  (6.767s)
.   7: Δ =   +2431.41  sum_log_prob =    -198912  prev =    -201343  'G2'  (6.142s)
.   8: Δ =   +3722.32  sum_log_prob =    -195189  prev =    -198912  'G2'  (5.628s)
.   9: Δ =   +3033.63  sum_log_prob =    -192156  prev =    -195189  'G2'  (6.018s)
.  10: Δ =   +2966.97  sum_log_prob =    -189189  prev =    -192156  'G2'  (5.832s)


	Model: data/hmms/N20__M4096_t3__a0.3_I10/G2.hmm   className: 'G2'
	N=20 M=4096 type: cascade-3
	restriction: 1e-05
	        #sequences: 246
	        auto value: 0.3
	      #refinements: 10
	          Σ log(P): -189189
=> training took 1m:1.7s     class=G2

